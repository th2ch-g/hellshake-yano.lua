import { assertEquals, assertExists } from "https://deno.land/std@0.224.0/assert/mod.ts";
import { describe, it } from "https://deno.land/std@0.224.0/testing/bdd.ts";
import {
  EnhancedHybridWordDetector,
  SegmentAnalyzer,
  TextSegment,
  TextPreProcessor,
  TextPostProcessor
} from "./enhanced-hybrid.ts";
import { Word } from "../types.ts";

describe("EnhancedHybridWordDetector", () => {
  describe("Segment Analysis Tests", () => {
    const analyzer = new SegmentAnalyzer();

    it("should identify pure Japanese text", () => {
      const text = "ã“ã‚Œã¯æ—¥æœ¬èªžã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚æ¼¢å­—ã¨ã²ã‚‰ãŒãªã‚’å«ã¿ã¾ã™ã€‚";
      const segments = analyzer.analyze(text);

      assertEquals(segments.length, 1);
      assertEquals(segments[0].type, "japanese");
      assertEquals(segments[0].confidence >= 0.8, true);
    });

    it("should identify pure English text", () => {
      const text = "This is an English text with various words and sentences.";
      const segments = analyzer.analyze(text);

      assertEquals(segments.length, 1);
      assertEquals(segments[0].type, "english");
      assertEquals(segments[0].confidence >= 0.8, true);
    });

    it("should identify mixed Japanese-English text", () => {
      const text = "ã“ã‚Œã¯mixedãƒ†ã‚­ã‚¹ãƒˆã§ã€English wordsã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚";
      const segments = analyzer.analyze(text);

      // æ··åœ¨ãƒ†ã‚­ã‚¹ãƒˆã¯è¤‡æ•°ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã•ã‚Œã‚‹
      assertEquals(segments.length > 1, true);
      const types = segments.map(s => s.type);
      assertEquals(types.includes("japanese"), true);
      assertEquals(types.includes("english"), true);
    });

    it("should identify code mixed text", () => {
      const text = "function hello() { console.log('Hello, ä¸–ç•Œ'); }";
      const segments = analyzer.analyze(text);

      // ã‚³ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã‚’èªè­˜
      const hasCode = segments.some(s => s.type === "code");
      assertEquals(hasCode, true);
    });

    it("should identify symbol-heavy text", () => {
      const text = "!@#$%^&*()_+-={}[]|\\:;<>?,./";
      const segments = analyzer.analyze(text);

      assertEquals(segments.length, 1);
      assertEquals(segments[0].type, "symbol");
    });

    it("should handle mixed numeric text", () => {
      const text = "ä¾¡æ ¼ã¯1,234å††ã§ã™ã€‚The price is $56.78.";
      const segments = analyzer.analyze(text);

      // æ•°å€¤ã‚’å«ã‚€æ··åœ¨ãƒ†ã‚­ã‚¹ãƒˆã®å‡¦ç†
      assertEquals(segments.length >= 2, true);
    });

    it("should process whitespace and newlines correctly", () => {
      const text = "  Line 1  \n\n  Line 2  \t\tTabbed  ";
      const segments = analyzer.analyze(text);

      // ç©ºç™½ã‚„æ”¹è¡ŒãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹
      assertExists(segments);
      assertEquals(segments.every(s => s.text.trim().length > 0), true);
    });

    it("should handle special characters properly", () => {
      const text = "çµµæ–‡å­—ðŸ˜€ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã‚„ã€ç‰¹æ®Šæ–‡å­—â„¢ï¸Â®ï¸Â©ï¸ã‚‚å‡¦ç†";
      const segments = analyzer.analyze(text);

      // ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã®å‡¦ç†
      assertExists(segments);
      assertEquals(segments.length >= 1, true);
    });
  });

  describe("Detector Selection Tests", () => {
    const detector = new EnhancedHybridWordDetector("enhanced-hybrid");

    it("should select TinySegmenter for Japanese text", async () => {
      const segments: TextSegment[] = [{
        text: "æ—¥æœ¬èªžã®ãƒ†ã‚­ã‚¹ãƒˆ",
        type: "japanese",
        confidence: 0.9,
        startIndex: 0,
        endIndex: 8
      }];

      const selectedDetector = detector.selectDetector(segments);
      assertEquals(selectedDetector.name.includes("tinysegmenter"), true);
    });

    it("should select RegExp detector for English text", async () => {
      const segments: TextSegment[] = [{
        text: "English text here",
        type: "english",
        confidence: 0.9,
        startIndex: 0,
        endIndex: 17
      }];

      const selectedDetector = detector.selectDetector(segments);
      assertEquals(selectedDetector.name.includes("regexp"), true);
    });

    it("should select Hybrid for mixed text", async () => {
      const segments: TextSegment[] = [
        {
          text: "æ··åœ¨",
          type: "japanese",
          confidence: 0.8,
          startIndex: 0,
          endIndex: 2
        },
        {
          text: "mixed",
          type: "english",
          confidence: 0.8,
          startIndex: 2,
          endIndex: 7
        }
      ];

      const selectedDetector = detector.selectDetector(segments);
      assertEquals(selectedDetector.name.includes("hybrid"), true);
    });

    it("should switch detector based on confidence threshold", async () => {
      const lowConfidenceSegments: TextSegment[] = [{
        text: "ambiguous text",
        type: "english",
        confidence: 0.3,  // Low confidence
        startIndex: 0,
        endIndex: 14
      }];

      const highConfidenceSegments: TextSegment[] = [{
        text: "clear text",
        type: "english",
        confidence: 0.95,  // High confidence
        startIndex: 0,
        endIndex: 10
      }];

      const detector1 = detector.selectDetector(lowConfidenceSegments);
      const detector2 = detector.selectDetector(highConfidenceSegments);

      // ä¿¡é ¼åº¦ã«ã‚ˆã£ã¦ç•°ãªã‚‹æ¤œå‡ºå™¨ãŒé¸æŠžã•ã‚Œã‚‹å¯èƒ½æ€§
      assertExists(detector1);
      assertExists(detector2);
    });

    it("should provide fallback on detector error", async () => {
      // ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ä¸æ­£ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
      const invalidSegments: TextSegment[] = [];

      const selectedDetector = detector.selectDetector(invalidSegments);
      assertExists(selectedDetector);  // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œå‡ºå™¨ãŒè¿”ã•ã‚Œã‚‹
    });

    it("should recover from errors gracefully", async () => {
      const detector = new EnhancedHybridWordDetector("enhanced-hybrid");

      // ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã‚’ç¶™ç¶š
      const result = await detector.detectWords("", 1);
      assertEquals(Array.isArray(result), true);
      assertEquals(result.length, 0);  // ç©ºã®é…åˆ—ã‚’è¿”ã™
    });
  });
});

describe("TextPreProcessor", () => {
  it("should normalize text before detection", () => {
    const processor = new TextPreProcessor();
    const input = "ã€€ã€€å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã€€ã€€and half-width spaces  ";
    const processed = processor.process(input);

    // æ­£è¦åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    assertEquals(processed.normalized.includes("ã€€ã€€"), false);
    assertEquals(processed.original, input);
  });
});

describe("TextPostProcessor", () => {
  it("should merge duplicate words", () => {
    const processor = new TextPostProcessor();
    const words: Word[] = [
      { text: "test", line: 1, col: 1 },
      { text: "test", line: 1, col: 1 },  // Duplicate
      { text: "word", line: 1, col: 6 }
    ];

    const processed = processor.process(words);
    assertEquals(processed.length, 2);  // Duplicates removed
  });
});